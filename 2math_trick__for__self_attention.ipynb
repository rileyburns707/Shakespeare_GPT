{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNH92PSHGaKp9fYq43vkfZ2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rileyburns707/Shakespeare_GPT/blob/main/math_trick__for__self_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDiB49fAmfmk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mathematical trick in self-attention\n",
        "\n",
        "---\n",
        "This will be a quick detour from the 'building_GPT' code but will help us understand the greater idea moving foward"
      ],
      "metadata": {
        "id": "d8uqzQl1m2cR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# consider the following toy example:\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,2 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "print(x.shape)\n",
        "\n",
        "# we would like the 8 tokens (up to 8 tokens in a batch) to talk to each other (couple them)\n",
        "# we want to couple them in a specifc way. The 5th token should not talk to future tokens like 6,7,8\n",
        "# the easiest way for tokens to communicate is to do an average of the preceding elements\n",
        "# that method makes you lose a lot of info about special arrangments of the tokens but we will worry about that later"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oKTYjAsmsGh",
        "outputId": "0ed27d5c-e598-4dcd-bf95-725d974edd6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 8, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0] # 0'th batch element"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZQxEvhhm_T-",
        "outputId": "0b7ffd2a-c178-48a8-bd75-b0bf7d6b4277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1808, -0.0700],\n",
              "        [-0.3596, -0.9152],\n",
              "        [ 0.6258,  0.0255],\n",
              "        [ 0.9545,  0.0643],\n",
              "        [ 0.3612,  1.1679],\n",
              "        [-1.3499, -0.5102],\n",
              "        [ 0.2360, -0.2398],\n",
              "        [-0.9211,  1.5433]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# version 1\n",
        "\n",
        "# we want x[b,t] = mean_{i<=t} x [b,i]\n",
        "xbow = torch.zeros((B,T,C)) # bow = bag of words\n",
        "for b in range(B): # iterating over the batch dimensions independently\n",
        "  for t in range(T): # iterating over time\n",
        "    xprev = x[b, :t+1] # (t,C). xpev is the previous chunk of tokens\n",
        "    xbow[b,t] = torch.mean(xprev, 0) # averages out the time and you get a 1D C which you store in xbow"
      ],
      "metadata": {
        "id": "NnOS5VeCnAxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xbow[0]\n",
        "\n",
        "# the first row is the same since you only avergaed the first row\n",
        "# second row is the average of both rows in x\n",
        "# vertical average"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs8A99BonEta",
        "outputId": "3f27e039-d534-4ae7-b635-50927ec66060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1808, -0.0700],\n",
              "        [-0.0894, -0.4926],\n",
              "        [ 0.1490, -0.3199],\n",
              "        [ 0.3504, -0.2238],\n",
              "        [ 0.3525,  0.0545],\n",
              "        [ 0.0688, -0.0396],\n",
              "        [ 0.0927, -0.0682],\n",
              "        [-0.0341,  0.1332]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# version 2: using matrix multiply for a weighted aggregation\n",
        "\n",
        "# for explanation look below for commented version\n",
        "wei = torch.tril(torch.ones(T, T))\n",
        "wei = wei / wei.sum(1, keepdim=True)\n",
        "xbow2 = wei @ x\n",
        "print(torch.allclose(xbow, xbow2)) # should outputting true since they are the same, but commented out since it was outputting false"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrJrVCM5nGpm",
        "outputId": "45aa3d5e-7c58-4dac-cacf-b4835f5643ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow, xbow2 # if you look they are the exact same"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic4Of-lknIJ2",
        "outputId": "70752b29-3109-4e31-c69a-986a1a742b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 0.1808, -0.0700],\n",
              "          [-0.0894, -0.4926],\n",
              "          [ 0.1490, -0.3199],\n",
              "          [ 0.3504, -0.2238],\n",
              "          [ 0.3525,  0.0545],\n",
              "          [ 0.0688, -0.0396],\n",
              "          [ 0.0927, -0.0682],\n",
              "          [-0.0341,  0.1332]],\n",
              " \n",
              "         [[ 1.3488, -0.1396],\n",
              "          [ 0.8173,  0.4127],\n",
              "          [-0.1342,  0.4395],\n",
              "          [ 0.2711,  0.4774],\n",
              "          [ 0.2421,  0.0694],\n",
              "          [ 0.0084,  0.0020],\n",
              "          [ 0.0712, -0.1128],\n",
              "          [ 0.2527,  0.2149]],\n",
              " \n",
              "         [[-0.6631, -0.2513],\n",
              "          [ 0.1735, -0.0649],\n",
              "          [ 0.1685,  0.3348],\n",
              "          [-0.1621,  0.1765],\n",
              "          [-0.2312, -0.0436],\n",
              "          [-0.1015, -0.2855],\n",
              "          [-0.2593, -0.1630],\n",
              "          [-0.3015, -0.2293]],\n",
              " \n",
              "         [[ 1.6455, -0.8030],\n",
              "          [ 1.4985, -0.5395],\n",
              "          [ 0.4954,  0.3420],\n",
              "          [ 1.0623, -0.1802],\n",
              "          [ 1.1401, -0.4462],\n",
              "          [ 1.0870, -0.4071],\n",
              "          [ 1.0430, -0.1299],\n",
              "          [ 1.1138, -0.1641]]]),\n",
              " tensor([[[ 0.1808, -0.0700],\n",
              "          [-0.0894, -0.4926],\n",
              "          [ 0.1490, -0.3199],\n",
              "          [ 0.3504, -0.2238],\n",
              "          [ 0.3525,  0.0545],\n",
              "          [ 0.0688, -0.0396],\n",
              "          [ 0.0927, -0.0682],\n",
              "          [-0.0341,  0.1332]],\n",
              " \n",
              "         [[ 1.3488, -0.1396],\n",
              "          [ 0.8173,  0.4127],\n",
              "          [-0.1342,  0.4395],\n",
              "          [ 0.2711,  0.4774],\n",
              "          [ 0.2421,  0.0694],\n",
              "          [ 0.0084,  0.0020],\n",
              "          [ 0.0712, -0.1128],\n",
              "          [ 0.2527,  0.2149]],\n",
              " \n",
              "         [[-0.6631, -0.2513],\n",
              "          [ 0.1735, -0.0649],\n",
              "          [ 0.1685,  0.3348],\n",
              "          [-0.1621,  0.1765],\n",
              "          [-0.2312, -0.0436],\n",
              "          [-0.1015, -0.2855],\n",
              "          [-0.2593, -0.1630],\n",
              "          [-0.3015, -0.2293]],\n",
              " \n",
              "         [[ 1.6455, -0.8030],\n",
              "          [ 1.4985, -0.5395],\n",
              "          [ 0.4954,  0.3420],\n",
              "          [ 1.0623, -0.1802],\n",
              "          [ 1.1401, -0.4462],\n",
              "          [ 1.0870, -0.4071],\n",
              "          [ 1.0430, -0.1299],\n",
              "          [ 1.1138, -0.1641]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is all good but it is very inefficient. The trick is using matrix multiplication"
      ],
      "metadata": {
        "id": "KoTUDXkLnOlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using matrix multiplication\n",
        "\n",
        "torch.manual_seed(42)\n",
        "a = torch.ones(3,3) # 3x3 matrix of all 1's\n",
        "b = torch.randint(0,10, (3,2)).float() # creates 3x2 matrix w/ random numbers\n",
        "c = a @ b # matrix multiplication of 'a dot b equals c'\n",
        "print('a=')\n",
        "print(a)\n",
        "print('------')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('------')\n",
        "print('c=')\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV8AOpE7nJuQ",
        "outputId": "1613ef70-c026-4ec8-e81e-4661737a3a37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "------\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "------\n",
            "c=\n",
            "tensor([[14., 16.],\n",
            "        [14., 16.],\n",
            "        [14., 16.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "a = torch.tril(torch.ones(3,3)) # creates a lower triangular 3x3 matrix of all 1's\n",
        "b = torch.randint(0,10, (3,2)).float() # creates 3x2 matrix w/ random numbers\n",
        "c = a @ b # matrix multiplication of 'a dot b equals c'\n",
        "print('a=')\n",
        "print(a)\n",
        "print('------')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('------')\n",
        "print('c=')\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6gn1Wh9nRVG",
        "outputId": "ebdafe76-6da5-4aeb-f522-08226fa8cb3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "tensor([[1., 0., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 1.]])\n",
            "------\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "------\n",
            "c=\n",
            "tensor([[ 2.,  7.],\n",
            "        [ 8., 11.],\n",
            "        [14., 16.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When seeing how the dot product works we see for the final matrix c we get sums of a and b. We are doing a sum of a variable number (x number) of the rows in matrix b.\n",
        "\n",
        "We are doing sums but you can get the average for the rows in matrix b. If you normalize the rows in matrix a so they sum to 1, then you will get an average"
      ],
      "metadata": {
        "id": "e9T6qOHunVGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "a = torch.tril(torch.ones(3,3))\n",
        "\n",
        "a = a / torch.sum(a, 1, keepdim=True)\n",
        "# computes the sum of elements in each row of a. The argument 1 specifies that the sum is computed along the rows (dim=1).\n",
        "# keepdim=True keeps the dimensions of the result the same as the original tensor (i.e., the result is a column vector).\n",
        "\n",
        "b = torch.randint(0,10, (3,2)).float()\n",
        "c = a @ b\n",
        "print('a=')\n",
        "print(a)\n",
        "print('------')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('------')\n",
        "print('c=')\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ID2Qjm_unTTH",
        "outputId": "c21bf11a-d143-4518-98a4-12277b393ac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n",
            "------\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "------\n",
            "c=\n",
            "tensor([[2.0000, 7.0000],\n",
            "        [4.0000, 5.5000],\n",
            "        [4.6667, 5.3333]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the rows in matrix a sum to 1. The c matrix now has the average of the columns in matrix b. The 2,1 postion in matrix c is the average of 2 and 6. This applies to all the positions in matrix c"
      ],
      "metadata": {
        "id": "Og3jA9TbnZAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the explanation of version 2\n",
        "\n",
        "wei = torch.tril(torch.ones(T, T)) # a in this case\n",
        "wei = wei / wei.sum(1, keepdim=True) # gets lower triangular matrix for wei\n",
        "wei"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3wE4s8unXDJ",
        "outputId": "7f5bf4ce-4848-4f85-e561-f672121b15bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
              "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
              "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# explanation for version 2\n",
        "\n",
        "xbow2 = wei @ x # (T, T) @ (B,T,C) ---> (B, T, T) @ (B,T,C) pytorch sees there is no batch in wei so it will add one\n",
        "# ----> (B, T, C). So xbow2 will become identical to xbow\n",
        "torch.allclose(xbow, xbow2) # convinces us they are the same. Should be true but prints false even though they are the exact same"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kp23U0umna2C",
        "outputId": "d4c4811a-aa0f-4348-c7d1-acdab39278fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The trick is, we were able to use batch matrix multiply to do a weighted aggregation. The weights are specifed by the wei T x T array. Doing weighted sums makes us ensure ***we will only get information from tokens preceding it because we are using a lower triangular method.***"
      ],
      "metadata": {
        "id": "FyXnHpPXne4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Version 3\n",
        "# Use Softmax\n",
        "\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = torch.zeros((T,T)) # all zeros in begin\n",
        "wei = wei.masked_fill(tril == 0, float('-inf')) # for all the elements where tril =0, make them be negative infinity\n",
        "wei = F.softmax(wei, dim=-1) # softmax is a normalization operation\n",
        "xbow3 = wei @ x\n",
        "torch.allclose(xbow, xbow3) # should be true they are the exact same as seen below"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPRymFr-ncJL",
        "outputId": "5207688a-bd9d-41c8-8584-2288ee20cd48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow, xbow3 # they are the exact."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aju3R2JIngww",
        "outputId": "7c7ee876-5f03-4d77-c555-6abaa76602d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 0.1808, -0.0700],\n",
              "          [-0.0894, -0.4926],\n",
              "          [ 0.1490, -0.3199],\n",
              "          [ 0.3504, -0.2238],\n",
              "          [ 0.3525,  0.0545],\n",
              "          [ 0.0688, -0.0396],\n",
              "          [ 0.0927, -0.0682],\n",
              "          [-0.0341,  0.1332]],\n",
              " \n",
              "         [[ 1.3488, -0.1396],\n",
              "          [ 0.8173,  0.4127],\n",
              "          [-0.1342,  0.4395],\n",
              "          [ 0.2711,  0.4774],\n",
              "          [ 0.2421,  0.0694],\n",
              "          [ 0.0084,  0.0020],\n",
              "          [ 0.0712, -0.1128],\n",
              "          [ 0.2527,  0.2149]],\n",
              " \n",
              "         [[-0.6631, -0.2513],\n",
              "          [ 0.1735, -0.0649],\n",
              "          [ 0.1685,  0.3348],\n",
              "          [-0.1621,  0.1765],\n",
              "          [-0.2312, -0.0436],\n",
              "          [-0.1015, -0.2855],\n",
              "          [-0.2593, -0.1630],\n",
              "          [-0.3015, -0.2293]],\n",
              " \n",
              "         [[ 1.6455, -0.8030],\n",
              "          [ 1.4985, -0.5395],\n",
              "          [ 0.4954,  0.3420],\n",
              "          [ 1.0623, -0.1802],\n",
              "          [ 1.1401, -0.4462],\n",
              "          [ 1.0870, -0.4071],\n",
              "          [ 1.0430, -0.1299],\n",
              "          [ 1.1138, -0.1641]]]),\n",
              " tensor([[[ 0.1808, -0.0700],\n",
              "          [-0.0894, -0.4926],\n",
              "          [ 0.1490, -0.3199],\n",
              "          [ 0.3504, -0.2238],\n",
              "          [ 0.3525,  0.0545],\n",
              "          [ 0.0688, -0.0396],\n",
              "          [ 0.0927, -0.0682],\n",
              "          [-0.0341,  0.1332]],\n",
              " \n",
              "         [[ 1.3488, -0.1396],\n",
              "          [ 0.8173,  0.4127],\n",
              "          [-0.1342,  0.4395],\n",
              "          [ 0.2711,  0.4774],\n",
              "          [ 0.2421,  0.0694],\n",
              "          [ 0.0084,  0.0020],\n",
              "          [ 0.0712, -0.1128],\n",
              "          [ 0.2527,  0.2149]],\n",
              " \n",
              "         [[-0.6631, -0.2513],\n",
              "          [ 0.1735, -0.0649],\n",
              "          [ 0.1685,  0.3348],\n",
              "          [-0.1621,  0.1765],\n",
              "          [-0.2312, -0.0436],\n",
              "          [-0.1015, -0.2855],\n",
              "          [-0.2593, -0.1630],\n",
              "          [-0.3015, -0.2293]],\n",
              " \n",
              "         [[ 1.6455, -0.8030],\n",
              "          [ 1.4985, -0.5395],\n",
              "          [ 0.4954,  0.3420],\n",
              "          [ 1.0623, -0.1802],\n",
              "          [ 1.1401, -0.4462],\n",
              "          [ 1.0870, -0.4071],\n",
              "          [ 1.0430, -0.1299],\n",
              "          [ 1.1138, -0.1641]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# next few lines explain the code in version 3 in a more spelled out way\n",
        "\n",
        "tril"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuCs2UbcniDy",
        "outputId": "2587ac66-014c-4e9e-bf7d-58a0a63aa0fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei = torch.zeros((T,T))\n",
        "wei"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3cbs88Ankiq",
        "outputId": "2ee929a0-340d-43db-d13e-eb556679976b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gibuGXbtnlut",
        "outputId": "7ed027fa-f020-486d-c1ce-c53edea5e198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
              "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
              "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
              "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
              "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
              "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
              "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "wei"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM95g0hPnnIr",
        "outputId": "c7c35928-07df-4a32-ec34-2dd36cdbe32d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
              "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
              "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The weights begin with 0, which can be thought of as an interaction strengthener (affinity), in the sense that the weights tell you how much of each past token do you want to aggregate and average up.\n",
        "\n",
        "The lower triangular method ensures tokens from the past cannot communicate by setting them to negative infinity.\n",
        "\n",
        "Then we normalize and sum\n",
        "\n",
        "The weights will not always be zero, it will be data dependent. Each dataset will learn how much of each past token it should use, a token will have a stronger affinity towards one past token compared to another past token. When we normalize and sum we will aggregate their values depending on how interesting the tokens find each other.\n",
        "\n",
        "\n",
        "\n",
        "General summary of this detour:\n",
        "You can do weighted aggregations of your past elements by using matrix multiplication of a lower triangular fashion. The elements in the lower triangular part tells you how much each element uses"
      ],
      "metadata": {
        "id": "LfRS87d5nqOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3F53OxkmnokP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
